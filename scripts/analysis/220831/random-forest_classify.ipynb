{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "import sklearn.ensemble \n",
    "import sklearn.model_selection\n",
    "import sklearn.inspection\n",
    "\n",
    "import findatree.io as io\n",
    "import findatree.descriptions as descriptions\n",
    "\n",
    "# Dictionaries: species_name to ba and vice versa\n",
    "species_id_to_name = descriptions.species_id_to_name()\n",
    "species_name_to_id = descriptions.species_name_to_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory: Processed tnr%.hdf5s\n",
    "dir_hdf5 = r\"C:\\Data\\lwf\\processed\\2020\\hdf5\"\n",
    "\n",
    "# Directory: Plots\n",
    "dir_plots = r\"C:\\Data\\lwf\\analysis\\220830_random-forrest\\plots\"\n",
    "\n",
    "# Directory: sklearn\n",
    "dir_sklearn = r\"C:\\Data\\lwf\\analysis\\220830_random-forrest\\sklearn\\v01\"\n",
    "\n",
    "# Save names:\n",
    "save_name_params = 'params.yaml'\n",
    "save_name_gridcv = 'grid.joblib'\n",
    "save_name_dataset = 'dataset.joblib'\n",
    "save_name_permutation_test_score = 'permutation_test_score.joblib'\n",
    "save_name_permutation_feature_importance = 'permutation_feature_importance.joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load: features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(io)\n",
    "df, params_df = io.allhdf5s_crowns_features_to_dataframe(dir_hdf5, crowns_type='crowns_human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign families: Conifers and Broadleaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(descriptions)\n",
    "\n",
    "# Define families by patterns\n",
    "family_patterns = [\n",
    "    'kiefer|fichte|tanne|douglasie|lärche', \n",
    "    'buche|eiche|ahorn|erle|birke|esche',\n",
    "]\n",
    "\n",
    "family_names = [\n",
    "    'conifers',\n",
    "    'broadleaf',\n",
    "]\n",
    "\n",
    "families = descriptions.species_groupby_families(family_patterns, family_names)\n",
    "family_ids = descriptions.species_id_to_family_id(df.ba.values, families)\n",
    "\n",
    "df = df.assign(\n",
    "    family = family_ids,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean-up: features\n",
    "* `inf` and `nan` removal\n",
    "* Filtering based on `['kkl', 'equivalent_diameter_area', 'min_bright_ndre', 'eccentricity']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 of 3895 crowns: At least one NaN in features\n",
      "After NaN removal: Shape of df = (3847, 281)\n",
      "After filtering: Shape of df = (3716, 281)\n"
     ]
    }
   ],
   "source": [
    "# Replace inf values with nans\n",
    "df = df.where(df != np.inf, np.nan)\n",
    "\n",
    "# Get rows containing missing values\n",
    "rows_isnull = df.isnull().any(axis=1)\n",
    "print(f\"{np.sum(rows_isnull)} of {len(df)} crowns: At least one NaN in features\")\n",
    "\n",
    "# Remove these rows\n",
    "df = df.loc[~rows_isnull, :]\n",
    "print(f\"After NaN removal: Shape of df = {df.shape}\")\n",
    "\n",
    "# Filtering\n",
    "query_str = 'kkl in [1, 2, 3]'\n",
    "query_str += ' and equivalent_diameter_area > 1'\n",
    "query_str += ' and min_bright_ndre > 0'\n",
    "query_str += ' and eccentricity > 0'\n",
    "query_str += ' and eccentricity < 1'\n",
    "\n",
    "df = df.query(query_str)\n",
    "print(f\"After filtering: Shape of df = {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search: Pattern in column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_max_chm\n",
      "x_max_light\n",
      "y_max_chm\n",
      "y_max_light\n",
      "x_mean\n",
      "y_mean\n",
      "x_min_bbox\n",
      "x_max_bbox\n",
      "y_min_bbox\n",
      "y_max_bbox\n",
      "x_min_bbox_bright\n",
      "x_max_bbox_bright\n",
      "y_min_bbox_bright\n",
      "y_max_bbox_bright\n"
     ]
    }
   ],
   "source": [
    "pattern = '^x_|^y'\n",
    "\n",
    "cols = list(df.columns)\n",
    "for col in cols:\n",
    "    if bool(re.search(pattern, col, re.IGNORECASE)):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info: Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of crowns        : 3716\n",
      "Mean number of crowns per tnr : 29.7\n",
      "__________________________________________________\n",
      "\n",
      "species_id| species_name                  | count\n",
      "--------------------------------------------------\n",
      "       134| Gemeine Kiefer                : 1517\n",
      "       118| Gemeine Fichte                : 888\n",
      "        20| Rotbuche                      : 425\n",
      "        48| Traubeneiche                  : 199\n",
      "       100| Weißtanne                     : 186\n",
      "       116| Europäische Lärche            : 108\n",
      "        51| Stieleiche                    : 81\n",
      "         7| Schwarzerle                   : 38\n",
      "        22| Gemeine Esche                 : 37\n",
      "        10| Gemeine Birke                 : 36\n",
      "       136| Douglasie                     : 33\n",
      "        13| Hainbuche                     : 32\n",
      "         5| Bergahorn                     : 23\n",
      "       129| Schwarzkiefer                 : 16\n",
      "        36| Kirsche                       : 14\n",
      "         1| Feldahorn                     : 14\n",
      "        53| Roteiche                      : 12\n",
      "        68| Winterlinde                   : 11\n",
      "       117| Japanische Lärche             : 11\n",
      "        62| Weide                         : 9\n",
      "        35| Aspe                          : 6\n",
      "        64| Vogelbeere                    : 5\n",
      "       133| Strobe                        : 4\n",
      "         4| Spitzahorn                    : 4\n",
      "        70| Bergulme                      : 3\n",
      "        56| Robinie                       : 1\n",
      "        65| Speierling                    : 1\n",
      "        66| Elsbeere                      : 1\n",
      "       103| Küstentanne                   : 1\n",
      "__________________________________________________\n",
      "\n",
      " family_id| family_name                   | count | species_names\n",
      "--------------------------------------------------\n",
      "         0| conifers                      : 2760  | ['Gemeine Fichte', 'Omorikafichte', 'Sitkafichte', 'Gemeine Kiefer', 'Schwarzkiefer', 'Zirbelkiefer', 'Bergkiefer', 'Weißtanne', 'Küstentanne', 'Edeltanne', 'Nordmannstanne', 'Europäische Lärche', 'Japanische Lärche', 'Douglasie']\n",
      "         1| broadleaf                     : 901   | ['Trauben- oder Stieleiche', 'Traubeneiche', 'Stieleiche', 'Zerreiche', 'Roteiche', 'Gemeine Birke', 'Moorbirke', 'Schwarzerle', 'Rotbuche', 'Grauerle', 'Hainbuche', 'Grünerle', 'Gemeine Esche', 'Bergahorn', 'Spitzahorn', 'Feldahorn']\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(descriptions)\n",
    "\n",
    "descriptions.print_summary(\n",
    "    df.tnr.values,\n",
    "    df.ba.values,\n",
    "    df.family.values,\n",
    "    families,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'query': query_str,\n",
    "    'classes':families,\n",
    "    'test_size': 0.25,\n",
    "    'cv_splits': 5,\n",
    "    'shuffle': True,\n",
    "    'scoring': 'accuracy',\n",
    "    'n_permutations': 20,\n",
    "    'n_repeats': 10,\n",
    "    'max_samples': 0.5,\n",
    "}\n",
    "\n",
    "# Save parameters\n",
    "io.list_of_dicts_to_yaml(os.path.join(dir_sklearn, save_name_params), [params])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Features and labels\n",
    "* Exclude terrestrial features\n",
    "* Exclude coordinates\n",
    "* Exclude non-family members\n",
    "\n",
    "Create extended labels `y_extend` with information about `['family', 'ba', 'sst', 'nbv']`, to check later if classficiation is dependent on these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (3661, 252)\n",
      "y.shape: (3661,)\n",
      "y_extend.shape: (3661, 6)\n",
      "Ratio in y: [#class=0]/[#class=1]: 3.1\n"
     ]
    }
   ],
   "source": [
    "# Terrestrial and identifaction feature names to be excluded\n",
    "terr_names = [\n",
    "    'id', 'tnr', 'family',\n",
    "    'enr', 'bnr', 'ba', 'bhd_2020', \n",
    "    'alter_2020', 'bk', 'kkl', 'nbv',\n",
    "    'sst', 'gilb', 'kommentar', 'sicherheit',\n",
    "]\n",
    "\n",
    "# Coordinate features pattern to be excluded\n",
    "coordinate_pattern = '^x_|^y_'\n",
    "\n",
    "# Get all columns\n",
    "x_names = list(df.columns)\n",
    "\n",
    "# Exclude terrestrial feature names\n",
    "x_names = [col for col in x_names if col not in terr_names]\n",
    "\n",
    "# Exclude coordinates\n",
    "x_names = [col for col in x_names if not bool(re.search(coordinate_pattern, col))]\n",
    "\n",
    "# Define features -> x\n",
    "x = df.loc[df.family >= 0, x_names].values\n",
    "\n",
    "# Define labels -> y\n",
    "y_names = ['family']\n",
    "y = df.loc[df.family >= 0, y_names[0]].values\n",
    "\n",
    "# Define extended labels -> y_extend\n",
    "y_extend_names = ['family', 'tnr', 'id', 'ba', 'sst', 'nbv']\n",
    "\n",
    "y_extend = df.loc[df.family >= 0, y_extend_names].values\n",
    "\n",
    "print(f\"x.shape: {x.shape}\")\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "print(f\"y_extend.shape: {y_extend.shape}\")\n",
    "print(f\"Ratio in y: [#class=0]/[#class=1]: {np.sum(y == 0) / np.sum(y == 1):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Data\\\\lwf\\\\analysis\\\\220830_random-forrest\\\\sklearn\\\\v01\\\\dataset.joblib']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, y_extend_train, y_extend_test, = sklearn.model_selection.train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    y_extend,\n",
    "    test_size=params['test_size'],\n",
    "    shuffle=True,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "dataset = {\n",
    "    'x_names': x_names,\n",
    "    'y_names': y_names,\n",
    "    'y_extend_names': y_extend_names,\n",
    "    'x_train': x_train,\n",
    "    'x_test': x_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'y_extend_train': y_extend_train,\n",
    "    'y_extend_test': y_extend_test,\n",
    "}\n",
    "\n",
    "# Save dataset\n",
    "joblib.dump(dataset, os.path.join(dir_sklearn, save_name_dataset)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grd.best_params_: {'criterion': 'entropy', 'max_samples': 0.75, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "grd.best_estimator_.score(x_test, y_test): 0.925\n"
     ]
    }
   ],
   "source": [
    "params_grd = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'max_samples': [0.75, 0.5]\n",
    "}\n",
    "grd = sklearn.model_selection.GridSearchCV(\n",
    "    sklearn.ensemble.RandomForestClassifier(n_jobs=-1),\n",
    "    param_grid = params_grd,\n",
    "    scoring  = params['scoring'],\n",
    "    cv = sklearn.model_selection.KFold(n_splits=params['cv_splits'], shuffle=params['shuffle'])\n",
    ")\n",
    "grd.fit(x_train, y_train)\n",
    "\n",
    "# Select best_estimator and retrain on complete training set\n",
    "rfc = grd.best_estimator_\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "# Save gridcv\n",
    "joblib.dump(grd, os.path.join(dir_sklearn, save_name_gridcv))\n",
    "\n",
    "# Best estimator\n",
    "print(f\"grd.best_params_: {grd.best_params_}\")\n",
    "print(f\"grd.best_estimator_.score(x_test, y_test): {grd.best_estimator_.score(x_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Estimator: Permutation Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Data\\\\lwf\\\\analysis\\\\220830_random-forrest\\\\sklearn\\\\v01\\\\permutation_test_score.joblib']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, permutation_score, pvalue = sklearn.model_selection.permutation_test_score(\n",
    "    grd.best_estimator_,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    cv=sklearn.model_selection.KFold(n_splits=params['cv_splits'], shuffle=params['shuffle']),\n",
    "    n_permutations=params['n_permutations'],\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Add result to params\n",
    "permutation_test_score = {\n",
    "    'permutation_scores':  permutation_score,\n",
    "    'test_score': score,\n",
    "    'pvalue': pvalue,\n",
    "}\n",
    "\n",
    "# Save permutation_test_score\n",
    "joblib.dump(permutation_test_score, os.path.join(dir_sklearn, save_name_permutation_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Estimator: Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Data\\\\lwf\\\\analysis\\\\220830_random-forrest\\\\sklearn\\\\v01\\\\permutation_feature_importance.joblib']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_imp_train = sklearn.inspection.permutation_importance(\n",
    "    grd.best_estimator_,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    n_repeats=params['n_repeats'],\n",
    "    max_samples=params['max_samples'],\n",
    ")\n",
    "\n",
    "# Sort according to importance\n",
    "sort_idx = np.flip(np.argsort(np.abs(perm_imp_train['importances_mean'])))\n",
    "\n",
    "# Add result to params\n",
    "permutation_feature_importance = {\n",
    "    'on': 'test',\n",
    "    'importances_mean': perm_imp_train['importances_mean'],\n",
    "    'importances_std': perm_imp_train['importances_std'],\n",
    "    'importances': perm_imp_train['importances'],\n",
    "}\n",
    "\n",
    "# Save permutation feature importances\n",
    "joblib.dump(permutation_feature_importance, os.path.join(dir_sklearn, save_name_permutation_feature_importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load: Previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_name = save_name_gridcv\n",
    "grd = joblib.load(os.path.join(dir_sklearn, load_name))\n",
    "\n",
    "load_name = save_name_params\n",
    "with open(os.path.join(dir_sklearn, load_name), \"r\") as f:\n",
    "    params = yaml.safe_load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('findatree_v01')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "635c494a99b4919ffc46b3179c211e3df0819f0dc50ebdacd534597eabf9f7f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
