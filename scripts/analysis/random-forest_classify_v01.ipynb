{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T20:57:29.837859Z",
     "start_time": "2022-10-29T20:57:21.176003Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "import sklearn.ensemble \n",
    "import sklearn.model_selection\n",
    "import sklearn.inspection\n",
    "\n",
    "import findatree.io as io\n",
    "import findatree.descriptions as descriptions\n",
    "\n",
    "# Dictionaries: species_name to ba and vice versa\n",
    "species_id_to_name = descriptions.species_id_to_name()\n",
    "species_name_to_id = descriptions.species_name_to_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T21:00:07.719263Z",
     "start_time": "2022-10-29T21:00:07.688022Z"
    }
   },
   "outputs": [],
   "source": [
    "# Directory: Processed tnr%.hdf5s\n",
    "dir_hdf5 = r\"C:\\Data\\lwf\\processed\\2020\\hdf5\"\n",
    "\n",
    "# Path to flight-log\n",
    "path_log = r\"C:\\Data\\lwf\\Flugbuch_WZE-2020_digitalisiert.csv\"\n",
    "\n",
    "# Directory: sklearn\n",
    "dir_sklearn = r\"C:\\Data\\lwf\\analysis\\221029_random_forest\\sklearn\\v01\"\n",
    "\n",
    "# Save names:\n",
    "save_name_params = 'params.yaml'\n",
    "save_name_gridcv = 'grid.joblib'\n",
    "save_name_dataset = 'dataset.joblib'\n",
    "save_name_permutation_test_score = 'permutation_test_score.joblib'\n",
    "save_name_permutation_feature_importance = 'permutation_feature_importance.joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load  features and logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T21:00:25.783652Z",
     "start_time": "2022-10-29T21:00:22.451956Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(io)\n",
    "\n",
    "# Load features\n",
    "df_original, params_df = io.allhdf5s_crowns_features_to_dataframe(dir_hdf5, crowns_type='crowns_human')\n",
    "\n",
    "# Load logbook\n",
    "log = pd.read_csv(path_log, sep=';', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Clean-up of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T21:01:02.600143Z",
     "start_time": "2022-10-29T21:01:02.442658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#crowns = 4254 (original)\n",
      "#crowns = 4158 (after removal: NaNs,  i.e. completely shadowed or dead)\n",
      "#crowns = 4127 (after removal: bk > 1)\n",
      "#crowns = 4127 (after removal: kkl > 3)\n",
      "#crowns = 4089 (after removal: #(bright pixels) <= 10)\n",
      "#crowns = 4067 (after removal: perc5_ndre < 1e-1)\n"
     ]
    }
   ],
   "source": [
    "# Copy original\n",
    "df = df_original.copy()\n",
    "print(f\"{r'#crowns'} = {len(df)} (original)\")\n",
    "\n",
    "# Convert bhd_2020 column to float32 dtype\n",
    "df.loc[:, 'bhd_2020'] = pd.to_numeric(df.bhd_2020, errors='coerce')\n",
    "df.bhd_2020 = df.bhd_2020.astype(np.float32)\n",
    "\n",
    "# Convert bk column to int32 dtype\n",
    "df.loc[:, 'bk'] = pd.to_numeric(df.bk, errors='coerce')\n",
    "df.bk = df.bk.astype(np.int32)\n",
    "\n",
    "# Drop NaN containing rows\n",
    "df = df.dropna(axis=0, how='any')   \n",
    "print(f\"{r'#crowns'} = {len(df)} (after removal: NaNs,  i.e. completely shadowed or dead)\")\n",
    "\n",
    "# Drop bk > 1\n",
    "df = df[df.bk <= 1]\n",
    "print(f\"{r'#crowns'} = {len(df)} (after removal: bk > 1)\")\n",
    "\n",
    "# Drop kkl > 3\n",
    "df = df[df.kkl <= 3]\n",
    "print(f\"{r'#crowns'} = {len(df)} (after removal: kkl > 3)\")\n",
    "\n",
    "# Drop area_bright/0.2**2 < 10\n",
    "df = df[df.area_bright / 0.2**2 > 10]\n",
    "print(f\"{r'#crowns'} = {len(df)} (after removal: #(bright pixels) <= 10)\")\n",
    "\n",
    "# Drop perc5_ndre < 0\n",
    "df = df[df.perc5_ndre > -1e-1]\n",
    "print(f\"{r'#crowns'} = {len(df)} (after removal: perc5_ndre < 1e-1)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign weather conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T21:01:05.002511Z",
     "start_time": "2022-10-29T21:01:04.935265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#tnrs = 81 -> sunny\n",
      "#tnrs = 47 -> cloudy\n",
      "#tnrs = 22 -> mixed\n",
      "\n",
      "#crowns = 2125 -> sunny\n",
      "#crowns = 1293 -> cloudy\n",
      "#crowns = 649 -> mixed\n"
     ]
    }
   ],
   "source": [
    "tnrs = log.Traktnummer.values\n",
    "weathers = log['Wetter-Code'].values\n",
    "tnr_to_weather = dict([(tnr, weather) for tnr, weather in zip(tnrs, weathers)])\n",
    "\n",
    "df['weather'] = [tnr_to_weather[tnr] for tnr in df.tnr]\n",
    "\n",
    "print(f\"#tnrs = {len(np.unique(df[df.weather == 0].tnr))} -> sunny\")\n",
    "print(f\"#tnrs = {len(np.unique(df[df.weather == 1].tnr))} -> cloudy\")\n",
    "print(f\"#tnrs = {len(np.unique(df[df.weather == 2].tnr))} -> mixed\")\n",
    "print()\n",
    "print(f\"#crowns = {np.sum(df.weather == 0)} -> sunny\")\n",
    "print(f\"#crowns = {np.sum(df.weather == 1)} -> cloudy\")\n",
    "print(f\"#crowns = {np.sum(df.weather == 2)} -> mixed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign families: Conifers and Broadleaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T21:02:45.248604Z",
     "start_time": "2022-10-29T21:02:45.202129Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(descriptions)\n",
    "\n",
    "# Define families by patterns\n",
    "family_patterns = [\n",
    "    'kiefer|fichte|tanne|douglasie|lärche', \n",
    "    'buche|eiche|ahorn|erle|birke|esche',\n",
    "]\n",
    "\n",
    "family_names = [\n",
    "    'conifers',\n",
    "    'broadleaf',\n",
    "]\n",
    "\n",
    "families = descriptions.species_groupby_families(family_patterns, family_names)\n",
    "family_ids = descriptions.species_id_to_family_id(df.ba.values, families)\n",
    "\n",
    "df = df.assign(\n",
    "    family = family_ids,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search: Pattern in column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '^x_|^y'\n",
    "\n",
    "cols = list(df.columns)\n",
    "for col in cols:\n",
    "    if bool(re.search(pattern, col, re.IGNORECASE)):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info: Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T21:02:59.635168Z",
     "start_time": "2022-10-29T21:02:59.614345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of crowns        : 4067\n",
      "Mean number of crowns per tnr : 27.1\n",
      "__________________________________________________\n",
      "\n",
      "species_id| species_name                  | count\n",
      "--------------------------------------------------\n",
      "       134| Gemeine Kiefer                : 1424\n",
      "       118| Gemeine Fichte                : 1215\n",
      "        20| Rotbuche                      : 489\n",
      "        48| Traubeneiche                  : 205\n",
      "       100| Weißtanne                     : 192\n",
      "        51| Stieleiche                    : 131\n",
      "       116| Europäische Lärche            : 115\n",
      "        22| Gemeine Esche                 : 53\n",
      "        10| Gemeine Birke                 : 45\n",
      "       136| Douglasie                     : 35\n",
      "         5| Bergahorn                     : 32\n",
      "         7| Schwarzerle                   : 27\n",
      "       129| Schwarzkiefer                 : 22\n",
      "        13| Hainbuche                     : 18\n",
      "        36| Kirsche                       : 15\n",
      "       117| Japanische Lärche             : 10\n",
      "        53| Roteiche                      : 9\n",
      "        35| Aspe                          : 7\n",
      "        62| Weide                         : 5\n",
      "         1| Feldahorn                     : 4\n",
      "        68| Winterlinde                   : 4\n",
      "       133| Strobe                        : 4\n",
      "        70| Bergulme                      : 2\n",
      "        65| Speierling                    : 1\n",
      "       103| Küstentanne                   : 1\n",
      "         4| Spitzahorn                    : 1\n",
      "        56| Robinie                       : 1\n",
      "__________________________________________________\n",
      "\n",
      " family_id| family_name                   | count | species_names\n",
      "--------------------------------------------------\n",
      "         0| conifers                      : 3014  | ['Gemeine Fichte', 'Omorikafichte', 'Sitkafichte', 'Gemeine Kiefer', 'Schwarzkiefer', 'Zirbelkiefer', 'Bergkiefer', 'Weißtanne', 'Küstentanne', 'Edeltanne', 'Nordmannstanne', 'Europäische Lärche', 'Japanische Lärche', 'Douglasie']\n",
      "         1| broadleaf                     : 1014  | ['Trauben- oder Stieleiche', 'Traubeneiche', 'Stieleiche', 'Zerreiche', 'Roteiche', 'Gemeine Birke', 'Moorbirke', 'Schwarzerle', 'Rotbuche', 'Grauerle', 'Hainbuche', 'Grünerle', 'Gemeine Esche', 'Bergahorn', 'Spitzahorn', 'Feldahorn']\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(descriptions)\n",
    "\n",
    "descriptions.print_summary(\n",
    "    df.tnr.values,\n",
    "    df.ba.values,\n",
    "    df.family.values,\n",
    "    families,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T21:03:51.707325Z",
     "start_time": "2022-10-29T21:03:51.667995Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'classes':families,\n",
    "    'test_size': 0.25,\n",
    "    'cv_splits': 5,\n",
    "    'shuffle': True,\n",
    "    'scoring': 'accuracy',\n",
    "    'n_permutations': 20,\n",
    "    'n_repeats': 10,\n",
    "    'max_samples': 0.5,\n",
    "}\n",
    "\n",
    "# Save parameters\n",
    "io.list_of_dicts_to_yaml(os.path.join(dir_sklearn, save_name_params), [params])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Features and labels\n",
    "* Exclude terrestrial features\n",
    "* Exclude coordinates\n",
    "* Exclude non-family members\n",
    "\n",
    "Create extended labels `y_extend` with information about `['family', 'ba', 'sst', 'nbv']`, to check later if classficiation is dependent on these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T21:05:47.246196Z",
     "start_time": "2022-10-29T21:05:47.178929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (4028, 108)\n",
      "y.shape: (4028,)\n",
      "y_extend.shape: (4028, 6)\n",
      "Ratio in y: [#class=0]/[#class=1]: 3.0\n"
     ]
    }
   ],
   "source": [
    "# Terrestrial and identifaction feature names to be excluded\n",
    "terr_names = [\n",
    "    'id', 'tnr', 'family',\n",
    "    'enr', 'bnr', 'ba', 'bhd_2020', \n",
    "    'alter_2020', 'bk', 'kkl', 'nbv',\n",
    "    'sst', 'gilb', 'kommentar', 'sicherheit',\n",
    "]\n",
    "\n",
    "# Coordinate features pattern to be excluded\n",
    "coordinate_pattern = '^x_|^y_'\n",
    "\n",
    "# Get all columns\n",
    "x_names = list(df.columns)\n",
    "\n",
    "# Exclude terrestrial feature names\n",
    "x_names = [col for col in x_names if col not in terr_names]\n",
    "\n",
    "# Exclude coordinates\n",
    "x_names = [col for col in x_names if not bool(re.search(coordinate_pattern, col))]\n",
    "\n",
    "# Define features -> x\n",
    "x = df.loc[df.family >= 0, x_names].values\n",
    "\n",
    "# Define labels -> y\n",
    "y_names = ['family']\n",
    "y = df.loc[df.family >= 0, y_names[0]].values\n",
    "\n",
    "# Define extended labels -> y_extend\n",
    "y_extend_names = ['family', 'tnr', 'id', 'ba', 'sst', 'nbv']\n",
    "\n",
    "y_extend = df.loc[df.family >= 0, y_extend_names].values\n",
    "\n",
    "print(f\"x.shape: {x.shape}\")\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "print(f\"y_extend.shape: {y_extend.shape}\")\n",
    "print(f\"Ratio in y: [#class=0]/[#class=1]: {np.sum(y == 0) / np.sum(y == 1):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T21:05:52.130975Z",
     "start_time": "2022-10-29T21:05:52.039705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Data\\\\lwf\\\\analysis\\\\221029_random_forest\\\\sklearn\\\\v01\\\\dataset.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, y_extend_train, y_extend_test, = sklearn.model_selection.train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    y_extend,\n",
    "    test_size=params['test_size'],\n",
    "    shuffle=True,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "dataset = {\n",
    "    'x_names': x_names,\n",
    "    'y_names': y_names,\n",
    "    'y_extend_names': y_extend_names,\n",
    "    'x_train': x_train,\n",
    "    'x_test': x_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'y_extend_train': y_extend_train,\n",
    "    'y_extend_test': y_extend_test,\n",
    "}\n",
    "\n",
    "# Save dataset\n",
    "joblib.dump(dataset, os.path.join(dir_sklearn, save_name_dataset)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T21:11:23.596467Z",
     "start_time": "2022-10-29T21:06:11.916843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grd.best_params_: {'criterion': 'entropy', 'max_samples': 0.75, 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "grd.best_estimator_.score(x_test, y_test): 0.930\n"
     ]
    }
   ],
   "source": [
    "params_grd = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'max_samples': [0.75, 0.5]\n",
    "}\n",
    "grd = sklearn.model_selection.GridSearchCV(\n",
    "    sklearn.ensemble.RandomForestClassifier(n_jobs=-1),\n",
    "    param_grid = params_grd,\n",
    "    scoring  = params['scoring'],\n",
    "    cv = sklearn.model_selection.KFold(n_splits=params['cv_splits'], shuffle=params['shuffle'])\n",
    ")\n",
    "grd.fit(x_train, y_train)\n",
    "\n",
    "# Select best_estimator and retrain on complete training set\n",
    "rfc = grd.best_estimator_\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "# Save gridcv\n",
    "joblib.dump(grd, os.path.join(dir_sklearn, save_name_gridcv))\n",
    "\n",
    "# Best estimator\n",
    "print(f\"grd.best_params_: {grd.best_params_}\")\n",
    "print(f\"grd.best_estimator_.score(x_test, y_test): {grd.best_estimator_.score(x_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Estimator: Permutation Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "score, permutation_score, pvalue = sklearn.model_selection.permutation_test_score(\n",
    "    grd.best_estimator_,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    cv=sklearn.model_selection.KFold(n_splits=params['cv_splits'], shuffle=params['shuffle']),\n",
    "    n_permutations=params['n_permutations'],\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Add result to params\n",
    "permutation_test_score = {\n",
    "    'permutation_scores':  permutation_score,\n",
    "    'test_score': score,\n",
    "    'pvalue': pvalue,\n",
    "}\n",
    "\n",
    "# Save permutation_test_score\n",
    "joblib.dump(permutation_test_score, os.path.join(dir_sklearn, save_name_permutation_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Estimator: Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Data\\\\lwf\\\\analysis\\\\220830_random-forrest\\\\sklearn\\\\v01\\\\permutation_feature_importance.joblib']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_imp_train = sklearn.inspection.permutation_importance(\n",
    "    grd.best_estimator_,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    n_repeats=params['n_repeats'],\n",
    "    max_samples=params['max_samples'],\n",
    ")\n",
    "\n",
    "# Add result to params\n",
    "permutation_feature_importance = {\n",
    "    'on': 'test',\n",
    "    'importances_mean': perm_imp_train['importances_mean'],\n",
    "    'importances_std': perm_imp_train['importances_std'],\n",
    "    'importances': perm_imp_train['importances'],\n",
    "}\n",
    "\n",
    "# Save permutation feature importances\n",
    "joblib.dump(permutation_feature_importance, os.path.join(dir_sklearn, save_name_permutation_feature_importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load: Previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_name = save_name_gridcv\n",
    "grd = joblib.load(os.path.join(dir_sklearn, load_name))\n",
    "\n",
    "load_name = save_name_params\n",
    "with open(os.path.join(dir_sklearn, load_name), \"r\") as f:\n",
    "    params = yaml.safe_load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "635c494a99b4919ffc46b3179c211e3df0819f0dc50ebdacd534597eabf9f7f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
